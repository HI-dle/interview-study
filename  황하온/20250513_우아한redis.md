# [우아한 테크 세미나] 우아한 Redis by 강대명님 
- 내용 정리해보기

## Cache 서버
### Cache 란?
- 후에 발생할 요청의 결과를 미리 저장해두었다가 빠르게 서비스해주는 것을 의미

### 왜?
- 파레토 법칙 (20:80) : 전체 요청의 80% 는 20%의 사용자에 의해 발생한다
  - 캐시를 적용하기에 적절

### Cache 구조
#### Look aside Cache
- 캐시에 데이터 존재 여부 확인 후 데이터 반환
- 캐시 미스 발생시, DB 에 조회하여 캐시 서버에 저장 후 반환

#### Write Back
- 데이터를 캐시에 우선 저장
  - 빠른 속도로 서비스가 가능
- 특정 시간동안 캐시에 저장된 데이터를 DB에 반영하고, 캐시에서 삭제 처리
- 장애 발생시 데이터 유실 가능성 존재
- 사용 예시
  - 로그 저장과 같이 실시간으로 발생하는 데이터를 선저장 해두었다가 후에 배치 처리 
  - 극단적으로 헤비한 Write 작업에 적용

### Redis의 개발 편의성
- Memcached 와 비교해서 Collection 자료구조를 제공하므로 개발 편의성이 존재
- 레디스는 싱글 스레드로 동작 / 자료구조가 Atomic 하므로, Race Condition 회피 가능

### 활용 예시
- Remote Data Store
  - 여러 서버 간 데이터 공유
- 인증 토큰 등을 저장 (Strings 또는 Hash)
- Ranking 보드로 사용 (Sorted Set)
- 유저 API Limit
- 잡 큐 (list)

## Collection
### Strings, List, Hash, Set, Sorted Set 등등
- Sorted set 의 score 는 double 자료형이므로 데이터 크기에 주의

### 주의사항
- 하나의 컬렉션에 너무 많은 아이템을 담지 않는다.
  - 10,000 개 이하 몇 천개 수준으로 유지하는 것 권장
- Expire는 Collection 전체에 걸림
  - 컬렉션 하나에 아이템이 너무 많으면 한꺼번에 많은 아이템 삭제하는 부하가 발생 가능함

## Redis 운영
### 메모리 관리 주의
- Physical Memory 이상을 사용하게 되면 문제 발생
  - **Swap** 이 있다면 Swap 을 사용하므로 해당 페이지 접근할 때마다 성능 저하 (디스크 I/O 인한)
  - Swap 이 없다면 OOM 등으로 서버 다운 발생 가능
- Maxmemory 설정
  - 정의한 정책(ex. lru, lfu 등)에 따라 Maxmemory를 초과하면 데이터 삭제 작업 수행
  - Memory allocator (ex. jemalloc) 의 구현에 따라 다르게 동작할 수 있음
    - 레디스는 jemalloc 에 의존하므로 자기 자신에게 할당된 정확한 메모리 크기를 알 수 없음
    - 메모리 파편화 발생 가능성
- 메모리 모니터링(RSS) 필수!
- 큰 메모리를 사용하는 instance 하나보다는 적은 메모리를 사용하는 instance 여러 개가 안전함
  - 특히 Write가 헤비한 경우 메모리를 1.x ~ 2 배 더 사용하게 될 수 있음
  - 관리는 불편하지만 운영 안정성이 올라감

#### 메모리 부족시 처리 방안
- 6 ~ 70 % 메모리 사용하는 경우
  - 더 메모리 큰 장비로 마이그레이션
- 특정 데이터를 제거하여 메모리 확보
  - 이미 swap 사용 중이라면 프로세스 재시작 필요함

#### 메모리를 줄이기 위한 설정
- Collection 들의 자료 구조
  - Hash -> HashTable 하나 더 사용
  - Sorted Set -> Skiplist 와 HashTable 사용
  - Set -> HashTable 사용
  - 해당 자료구조들은 메모리를 많이 사용하게 됨
- Ziplist 를 이용하자
  - Collection 들의 자료 구조를 Ziplist를 사용하도록 설정해줄 수 있음

#### Ziplist 구조 활용
- 데이터 사용 최적화를 위해 redis 에서 사용하는 자료 구조
  - 포인터 사용을 최소화하여 데이터 오버헤드를 줄이는 형태
- 인메모리 특성성, 적은 개수(100개 정도라면)라면 풀 서치(선형 탐색)하더라도 빠르다
- List, Hash, Sorted set 등의 자료구조를 특정 사이즈까지는 ziplist 사용하도록 설정할 수 있음
  - 2 ~ 30 % 메모리 절약 가능

### O(N) 명령어 주의
- 레디스는 싱글 스레드이므로 동시에 처리할 수 있는 명령어는 한 번에 하나
  - 단순한 get/set 명령어의 경우 초당 10만 TPS 이상 가능
    - 하나의 명령에서 지연이 발생하는 경우 문제 상황이 발생할 수 있음
- 긴 시간을 수행하는 명령어 사용 금지

#### 대표적인 O(N) 명령들
- KEYS
  - 특히 key가 백 만 개 이상인 경우
  - scan 명령어로 대체 가능
    - 커서 기반으로 동작 수행
    - 긴 명령을 짧은 여러 번의 명령어로 대체
- FLUSHALL, FLUSHDB
- Delete Collections
  - 백 만 개 이상 지우려면 1~2초 소요됨
- Get All Collections
  - 몇 만 ~ 십 만 개 아이템을 넣고 가져오는 경우

#### Collection 의 모든 item 을 가져와야 하는 경우?
- Sorted set 등을 사용하여 일부만 가져오기
- 큰 Collection을 작은 여러 개의 Collection으로 나누어서 저장
  - 하나당 몇 천개 안쪽으로 저장
  - 여러 개의 키를 관리해야 하는 단점

## Replication
- Async Replication으로 동작
  - Replication Lag 가 발생할 수 있음
- Replicaof (>= 5.0.0 redis version) / Slaveof 명령어로 설정 가능
  - Replicaof hostname port
    - 프라이머리 정보 설정
- statement replication 과 유사하게 동작
  - row 기반이 아닌 쿼리로 동작
  - 시간 데이터 생성시 갭이 발생
    - 루아 스크립트 사용시 경우에 따라 다른 값이 나올 수 있음

### Replication 설정 과정
- Secondary 에 replicaof 명령을 전달
- Secondary 는 Primary에 sync 명령 전달
- Primary 는 현재 메모리 상태를 저장하기 위해 Fork 수행
- Fork 한 프로세서는 현재 메모리 정보를 disk에 dump
- 해당 정보를 Secondary에 전달
- Fork 이후의 데이터를 Secondary에 계속 전달

### 주의할 점
- Fork 가 발생하므로 메모리 부족 발생할 수 있음
- Redis-cli --rdb 명령은 현재 상태의 메모리 스냅샷을 가져오므로 같은 문제 발생 가능성 존재
- AWS 등의 클라우드에서는 다르게 구현되어 좀 더 나은 상황
- 많은 대수의 Redis 서버가 Replica를 두고 있다면
  - 네트웍 이슈나 사람의 작업으로 동시에 replication 이 재시도 되도록 하면 네트웍 등의 문제가 발생할 수 있음

### redis.conf 권장 설정
- Maxclinet 설정 50,000
- RDB/AOF 설정 off
  - replication/secondary 에서만 on 해두는 편
- 특정 명령어 disable
  - keys 등
- 전체 장애의 90% 이상이 keys 와 save 설정을 사용해서 발생
- 적절한 ziplist 설정

## Redis 데이터 분산
- 데이터의 특성에 따라 선택 가능한 방법이 달라짐
- cache 일 때는 대개 우아한 레디스
- persistent store 로 사용해야하 는 경우에는 우아하지 않음
  - 헬게이트 오픈

### Application 레벨
#### Consistent Hashing
- 자신의 해시값보다 크고 가장 가까운 해시값을 가진 서버로 할당
- 리밸런싱이 적게 발생

##### Modular
- N % K 값으로 데이터 분산
- 서버가 추가/장애로 삭제 될 때마다 데이터 리밸런싱 발생
- 장애에 취약
- 위에 대한 대안으로 배수로 서버를 증설할 수 있음
  - 리밸런싱이 조금 단순해짐

#### Sharding
- 데이터(키)를 어떻게 나눌 것인가 == 어떻게 찾을 것인가?
- 상황마다 샤딩 전략이 달라질 수 있음

##### Range
- 특정 범위를 정의하고, 범위에 따라 할당
  - 레디스 서버 상황에 따라 부하가 쏠릴 수 있음
  - 특정 헤비 유저가 존재하거나, 이벤트로 인한 일시적 부하 

##### indexed
- 인덱스 값을 저장하는 레디스 서버를 따로 두고 이를 통해 데이터 분산 처리
  - 균등하게 분산 조정 가능

### Redis Cluster
- Hash 기반으로 slot 16384 로 구분
  - CRC16 해시 알고리즘을 사용
  - slot = crc16(key) % 16384
- 레디스 서버는 slot range 를 가지고 있어서 데이터 마이그레이션은 slot 단위로 처리 
  - 수동작업 필요
- 라이브러리 의존성이 생길 수 있음
  - MOVED 오류 등

#### 장점
- 자체적인 Primary, Secondary Failover(헬스체크, 리더 선출)
- slot 단위의 데이터 관리

#### 단점
- 메모리 사용량이 더 많음
- Migration 자체는 관리자가 시점을 결정해야 함
- 라이브러리 구현이 필요함

## Redis Failover
### Coordinator 기반
- Zookeepe, etcd, consul 등 Coordinator 사용 가능
- 설정을 동일한 방식으로 관리할 수 있음
- 기능을 이용하도록 추가 개발이 필요

### VIP/DNS 기반
- 클라이언트에 추가적인 구현이 필요없다.
- VIP 기반은 외부로 서비스를 제공해야 하는 서비스 업자에 유리
  - 예를 들어 클라우드 업체
- DNS 기반은 DNS Cache TTL 을 관리해야 함
  - 사용하는 언어별 DNS 캐싱 정책을 잘 알고 정책 수립 필요
  - 툴에 따라 한번 가져오 DNS 정보를 다시 쿼리 하지 않을 수도 있음
#### VIP
- Virtual IP 을 할당해주고, 이를 기준으로 레디스 서버 접근
  - 장애 발생시 Secondary 에 vip 할당해서 연결 유도 가능 Failover
#### DNS
- 도메인 네임 서버를 할당해주고, 이를 기준으로 레디스 서버 접근

## Monitoring
### Redis Info
- RSS(Resident Set Size) : 데이터를 포함해서 실제로 레디스 서버에 할당 된 메모리 크기, Used Memory 에 비해 크게 나타날 수 있음(메모리 파편화 문제 등)
- Used Memory : 실제로 사용되고 있는 메모리 수
- Connection 수 : 커넥션을 유지하는 것이 서버가 안정된 것
- 초당 처리 요청 수

### System
- CPU
- Disk
- Network rx/tx

#### CPU 100% 치는 경우
- 처리량이 매우 많은 경우
  - 좀 더 성능이 좋은 CPU를 사용하는 서버로 이전 필요
- O(N) 계열의 특정 명령이 많은 경우
  - Monitor 명령을 통해 특정 패턴을 파악할 필요
  - Monitor 명령 잘못 쓰면 부하가 발생하므로 짧게 써야 함

## 결론
- 기본적으로 레디스는 매우 좋은 툴
- 메모리를 빡빡하게 쓸 경우 관리 어려움
  - 32 기가 장비라면 24 기가 이상 사용하는 경우 장비 증설 고려
  - Write 가 헤비한 경우 마이그레이션에 주의 필요
- Client-output-buffer-limit 설정에 주의 필요

### Redis as Cache
- Cache 일 경우는 문제가 적게 발생
  - Redis에 문제가 있을 때 DB 부하가 어느정도인지 확인 필요
- Consistent Hashing 도 부하를 아주 균등하게 나누지는 않음
  - Adaptive Consistent Hashing 적용 고려

### Redis as Persistent Store
- 무조건 Primary/Secondary 구조로 구성 필요
- 메모리를 절대 빡빡하게 사용하면 안됨
  - 정기적인 migration 필요
  - 가능하면 자동화 툴 만들어서 이용
  - RDB/AOF 가 필요하다면 Secondary 에서만 구동
    - RDB 보다는 AOF 가 I/O 가 균등하게 발생하는 편이므로 조금 더 추천
- 답 없음, 돈이 많이 들고 모니터링 꼼꼼하게 수행할 필요