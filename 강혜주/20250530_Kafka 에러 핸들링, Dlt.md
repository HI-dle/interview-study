## 시작하며

메시지 큐를 사용하다 보면 피할 수 없는 것이 바로 메시지 처리 실패다. 네트워크 장애, 외부 API 오류, 일시적 서버 문제 등 다양한 이유로 메시지 처리가 실패할 수 있다.
오늘은 Kafka에서 DLT(Dead Letter Topic)와 재처리 전략을 통해 메시지 처리 안정성을 높이는 방법을 살펴보겠다.

----

## DLT + 단계별 재처리
### 1단계: 일반 재시도 (kafkaErrorHandler)

- **재시도 간격**: 200ms
- **최대 재시도**: 5번
- **대상**: 일시적 오류 (네트워크 장애, API 제한 등)

기본 설정
```java
public DefaultErrorHandler() {  
  this(null, SeekUtils.DEFAULT_BACK_OFF);  
}
```

```java
public final class SeekUtils {

public static final int DEFAULT_MAX_FAILURES = 10;
public static final FixedBackOff DEFAULT_BACK_OFF = new FixedBackOff(0, DEFAULT_MAX_FAILURES - 1);

...
}
```

### 2단계: DLT 재처리 (dltKafkaErrorHandler)

- **재시도 간격**: 1초
- **최대 재시도**: 3번
- **대상**: 1단계에서 실패한 메시지

### 3단계: 최종 실패 처리

- 실패 로그 기록
- 실패 이벤트 발송 (필요시)
- 메시지 폐기

---

## 코드 구현

### Error Handler 설정

```java
@Slf4j
@Configuration
public class PaymentKafkaErrorHandlerConfig {

  private static final String DLT_SUFFIX = "-dlt";

  @Bean
  public <T> DeadLetterPublishingRecoverer deadLetterPublishingRecoverer(
      KafkaTemplate<String, T> kafkaTemplate) {
    return new DeadLetterPublishingRecoverer(
        kafkaTemplate,
        (ConsumerRecord<?, ?> record, Exception ex) -> {
          log.error("메시지 처리 실패: topic={}, partition={}, offset={}, exception={}",
              record.topic(), record.partition(), record.offset(), ex.getMessage());
          return new TopicPartition(record.topic()+DLT_SUFFIX, record.partition());
        }
    );
  }

  @Bean
  public DefaultErrorHandler kafkaErrorHandler(DeadLetterPublishingRecoverer recoverer) {
    return new DefaultErrorHandler(recoverer, new FixedBackOff(200L, 5));
  }

  @Bean
  public DefaultErrorHandler dltKafkaErrorHandler() {
    return new DefaultErrorHandler(
        (record, exception) -> {
      log.warn("DLT에서 메시지 최종 처리 실패: topic={}, partition={}, offset={}, key={}",
          record.topic(), record.partition(), record.offset(), record.key());
      log.warn("최종 실패 예외 내용: {}", exception.getMessage());
      log.warn("실패한 메시지 내용: {}", record.value());
    },
        new FixedBackOff(1000L, 3));
  }
}
```

### Consumer 설정

```java
@EnableKafka
@Configuration
@RequiredArgsConstructor
public class PaymentKafkaConsumerConfig {

  // ... 기타 설정들

  @Bean
  public ConcurrentKafkaListenerContainerFactory<String, ReservationCancelledEvent>
  reservationCancelledEventListenerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, ReservationCancelledEvent> factory =
        createContainerFactory(
            reservationCancelledEventConsumerFactory(),
            EventType.RESERVATION_CANCELLED.name()
        );

    factory.setCommonErrorHandler(kafkaErrorHandler); // 일반 에러 핸들러
    return factory;
  }

  @Bean
  public ConcurrentKafkaListenerContainerFactory<String, ReservationCancelledEvent>
  reservationCancelledEventDltListenerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, ReservationCancelledEvent> factory =
        createContainerFactory(
            reservationCancelledEventDltConsumerFactory(),
            EventType.RESERVATION_CANCELLED.name()
        );

    factory.setCommonErrorHandler(dltKafkaErrorHandler); // DLT 에러 핸들러
    factory.getContainerProperties().setAckMode(AckMode.MANUAL);
    factory.setConcurrency(dltConcurrency);
    return factory;
  }
}
```

### Topic 설정

```java
@Configuration
public class PaymentKafkaTopicConfig {

  private static final String PAYMENT_TOPIC_NAME = "payment-event";
  private static final String RESERVATION_DLT_NAME = "reservation-event-dlt";

  @Bean
  public NewTopic createTopic() {
    return TopicBuilder.name(PAYMENT_TOPIC_NAME)
        .partitions(3)
        .replicas(1)
        .config("min.insync.replicas", "1")
        .build();
  }

  @Bean
  public NewTopic createReservationDeadLetterTopic() {
    return TopicBuilder.name(RESERVATION_DLT_NAME)
        .partitions(3)
        .replicas(1)
        .build();
  }
}
```

---

## 고려사항

### 1. 선택적 재시도 전략

모든 예외를 재시도하는 것은 비효율적이다. 다음과 같이 구분해서 처리하는 것이 좋다:

```java
// 재시도하면 안 되는 예외들
- SerializationException: 직렬화/역직렬화 오류
- IllegalArgumentException: 잘못된 데이터 형식
- AuthenticationException: 인증 실패

// 재시도해야 하는 예외들  
- ConnectTimeoutException: 네트워크 타임아웃
- HttpStatus.TOO_MANY_REQUESTS: API 제한
- TransientDataAccessException: 일시적 DB 오류
```

### 2. DLT 파티션 전략

DLT는 원본 토픽과 동일한 파티션을 유지한다. 이렇게 하면

- 메시지 순서가 보장됨
- 파티션별로 독립적인 DLT 처리 가능
- 장애 복구 시 부분적 재처리 가능

### 3. 수동 Acknowledge

DLT에서는 수동 ACK를 사용한다:

```java
 factory.getContainerProperties().setAckMode(AckMode.MANUAL);
```

- 정확히 처리된 메시지만 ACK
- 부분 실패 시에도 안전한 처리
- 재시작 시 안전한 오프셋 관리

---

## 처리 흐름

```
[메시지 수신] 
    ↓
[비즈니스 로직 처리]
    ↓ (실패)
[200ms 간격으로 5회 재시도] 
    ↓ (여전히 실패)
[DLT로 이동]
    ↓
[1초 간격으로 3회 재시도]
    ↓ (최종 실패)
[실패 로그 + 이벤트 발송 + 메시지 폐기]
```

---

## 운영상 고려사항

### 1. 모니터링

- DLT 메시지 수 모니터링
- 재시도 실패율 추적
- 특정 에러 패턴 분석

### 2. 알림 설정

- DLT 메시지 발생 시 즉시 알림
- 재시도 실패율 임계값 설정
- 특정 예외 타입별 알림

### 3. 복구 전략

- 시스템 복구 후 DLT 메시지 재처리
- 배치 단위 DLT 처리
- 수동 재처리 도구 준비

---

## 마치며

DLT와 재처리 전략은 메시지 기반 시스템의 안정성을 크게 높여준다. 하지만 무분별한 재시도는 오히려 시스템에 부하를 줄 수 있으니, 예외 타입별로 적절한 전략을 수립하는 것이 중요하다.

특히 외부 API의 429(Too Many Requests) 같은 제한에 걸렸을 때만 재처리하고, 역직렬화 오류같은 구조적 문제는 즉시 폐기하는 것이 효율적이다.
